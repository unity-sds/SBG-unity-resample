{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7940462-0604-453e-bb6f-5a1d21c0800b",
   "metadata": {},
   "source": [
    "SBG - Spectral Resample Process - Application Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e2815e-0ec7-4b9e-a127-7a835de23370",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sister/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-15 21:35:37,553\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import hytools as ht\n",
    "from hytools.io.envi import WriteENVI\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from skimage.util import view_as_blocks\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import spectral.io.envi as envi\n",
    "import datetime as dt\n",
    "from unity_sds_client.resources.dataset import Dataset\n",
    "from unity_sds_client.resources.data_file import DataFile\n",
    "\n",
    "# stage_in packages\n",
    "from unity_sds_client.resources.collection import Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599c2b5-c346-43f1-bb38-42efe12fb557",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Resampling Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf65dcf7-6acd-41d0-a69b-ce94655f7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata(in_file,out_file,metadata):\n",
    "\n",
    "    with open(in_file, 'r') as in_obj:\n",
    "        in_met =json.load(in_obj)\n",
    "\n",
    "    for key,value in metadata.items():\n",
    "        in_met[key] = value\n",
    "\n",
    "    with open(out_file, 'w') as out_obj:\n",
    "        json.dump(in_met,out_obj,indent=3)\n",
    "\n",
    "def gaussian(x,mu,fwhm):\n",
    "\n",
    "    c = fwhm/(2* np.sqrt(2*np.log(2)))\n",
    "    return np.exp(-1*((x-mu)**2/(2*c**2)))\n",
    "\n",
    "def resample(in_file,out_file):\n",
    "\n",
    "    image = ht.HyTools()\n",
    "    image.read_file(in_file,'envi')\n",
    "\n",
    "    if image.wavelengths.max()< 1100:\n",
    "        new_waves = np.arange(400,991,10)\n",
    "    else:\n",
    "        new_waves = np.arange(400,2501,10)\n",
    "\n",
    "    bins = int(np.round(10/np.diff(image.wavelengths).mean()))\n",
    "    agg_waves  = np.nanmean(view_as_blocks(image.wavelengths[:(image.bands//bins) * bins],\n",
    "                                           (bins,)),axis=1)\n",
    "\n",
    "    if bins ==1 :\n",
    "        agg_fwhm  = image.fwhm\n",
    "\n",
    "    else:\n",
    "        hi_res_waves = np.arange(300,2600)\n",
    "        fwhm_array = np.zeros((image.bands,2600-300))\n",
    "\n",
    "        for i,(wave,fwhm) in enumerate(zip(image.wavelengths,image.fwhm)):\n",
    "            fwhm_array[i] = gaussian(hi_res_waves,wave,fwhm)\n",
    "\n",
    "        sum_fwhm  = np.nansum(view_as_blocks(fwhm_array[:(image.bands//bins) * bins],\n",
    "                                               (bins,2600-300)),axis=(1,2))\n",
    "        agg_fwhm = []\n",
    "        for i in range(len(agg_waves)):\n",
    "            arg_max = np.argmax(sum_fwhm[i])\n",
    "            half_max =  sum_fwhm[i].max()/2\n",
    "            diff = np.abs(sum_fwhm[i]-half_max)\n",
    "            end = arg_max + np.argmin(diff[arg_max:])\n",
    "            start = np.argmin(diff[:arg_max])\n",
    "            agg_fwhm.append(hi_res_waves[end] - hi_res_waves[start])\n",
    "\n",
    "    #True resampled FWHM is difficult to determine, using a simple nearest neighbor approximation\n",
    "    resampled_fwhm = interp1d(agg_waves,agg_fwhm,fill_value = 'extrapolate', kind = 'nearest')(new_waves)\n",
    "\n",
    "    print(f\"Aggregating every {bins} bands\")\n",
    "\n",
    "    out_header = image.get_header()\n",
    "    out_header['bands'] = len(new_waves)\n",
    "    out_header['wavelength'] = new_waves.tolist()\n",
    "    out_header['fwhm'] = resampled_fwhm\n",
    "    out_header['default bands'] = []\n",
    "\n",
    "    if  \"UNC\" in in_file:\n",
    "        out_header['description'] ='10 nm resampled reflectance uncertainty'\n",
    "    else:\n",
    "        out_header['description'] ='10 nm resampled reflectance'\n",
    "\n",
    "    writer = WriteENVI(out_file,out_header)\n",
    "    iterator =image.iterate(by = 'line')\n",
    "\n",
    "    while not iterator.complete:\n",
    "        line = iterator.read_next()[:,:(image.bands//bins) * bins]\n",
    "        line  = np.nanmean(view_as_blocks(line,(1,bins,)),axis=(2,3))\n",
    "        interpolator = interp1d(agg_waves,line,fill_value = 'extrapolate', kind = 'cubic')\n",
    "        line = interpolator(new_waves)\n",
    "        writer.write_line(line,iterator.current_line)\n",
    "\n",
    "def generate_quicklook(input_file):\n",
    "\n",
    "    img = ht.HyTools()\n",
    "    img.read_file(input_file)\n",
    "    image_file = input_file.replace('.bin','.png')\n",
    "\n",
    "    if 'DESIS' in img.base_name:\n",
    "        band3 = img.get_wave(560)\n",
    "        band2 = img.get_wave(850)\n",
    "        band1 = img.get_wave(660)\n",
    "    else:\n",
    "        band3 = img.get_wave(560)\n",
    "        band2 = img.get_wave(850)\n",
    "        band1 = img.get_wave(1660)\n",
    "\n",
    "    rgb=  np.stack([band1,band2,band3])\n",
    "    rgb[rgb == img.no_data] = np.nan\n",
    "\n",
    "    rgb = np.moveaxis(rgb,0,-1).astype(float)\n",
    "    bottom = np.nanpercentile(rgb,5,axis = (0,1))\n",
    "    top = np.nanpercentile(rgb,95,axis = (0,1))\n",
    "    rgb = np.clip(rgb,bottom,top)\n",
    "    rgb = (rgb-np.nanmin(rgb,axis=(0,1)))/(np.nanmax(rgb,axis= (0,1))-np.nanmin(rgb,axis= (0,1)))\n",
    "    rgb = (rgb*255).astype(np.uint8)\n",
    "\n",
    "    im = Image.fromarray(rgb)\n",
    "    im.save(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29748c49-101b-45ad-b7f0-079c87712b0c",
   "metadata": {},
   "source": [
    "Inputs and Configurations\n",
    "\n",
    "In the original pre-process, inputs are supplied by a run_config file. This consists of 2 entries (a reflectance file, uncertainty file, and a CRID).\n",
    "\n",
    "In the Unity system, the data files required will be staged in for the application, and the crid is a config item that is passed in. To make this work in Unity, we will also pass in an \"output collection\" which is needed if we want to \"persist\" the output products in the data catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbc6339-b4ee-4282-ae70-ff8c017f9f5c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#Retrieve Reflectance Dataset\n",
    "input_resample_dataset    = '/unity/ads/input_collections/SBG-L2A-RESAMPLE/catalog.json' # type: stage-in\n",
    "output_stac_catalog_dir   = '/unity/ads/outputs/SBG-L2A-RESAMPLE/' # type: stage-out\n",
    "\n",
    "output_collection_name    = 'example-L2A-Resample-Collect'\n",
    "\n",
    "#Pre-process variables\n",
    "#From the config.json, retrieve the following information:\n",
    "crid = \"000\" #hardcoded but will be passed in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265c43f-b678-4900-ab81-24cb13c89635",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Import Files from STAC Item Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202ee5b4-03bf-4e06-9a5f-4a1ca2f1ae4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/unity/ads/input_collections/SBG-L2A-RESAMPLE/SISTER_EMIT_L2A_RFL_20231206T160939_001.bin',\n",
       " '/unity/ads/input_collections/SBG-L2A-RESAMPLE/SISTER_EMIT_L2A_RFL_20231206T160939_001_UNC.bin']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_collection = Collection.from_stac(input_resample_dataset)\n",
    "data_filenames = inp_collection.data_locations()\n",
    "\n",
    "data_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35d73f-1188-43de-91b6-e8ab728543bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get the data files from the STAC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "400c89d8-c346-4ef1-8e42-55cba88a8005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflectance File:/unity/ads/input_collections/SBG-L2A-RESAMPLE/SISTER_EMIT_L2A_RFL_20231206T160939_001.bin\n",
      "Output path:/unity/ads/outputs/SBG-L2A-RESAMPLE//SISTER_EMIT_L2A_RSRFL_20231206T160939_000.met.json\n",
      "Uncertainty File:SISTER_EMIT_L2A_RFL_20231206T160939_001_UNC\n",
      "Output path:/unity/ads/outputs/SBG-L2A-RESAMPLE//SISTER_EMIT_L2A_RSRFL_20231206T160939_000_UNC.met.json\n"
     ]
    }
   ],
   "source": [
    "for f in data_filenames:\n",
    "    if \"_UNC.bin\" in f:\n",
    "        unc_base_name = Path(f).stem\n",
    "        unc_file = f\n",
    "    elif \".bin\" in f:\n",
    "        rfl_base_name = Path(f).stem\n",
    "        rfl_file = f\n",
    "\n",
    "print(rfl_base_name)\n",
    "print(unc_base_name)\n",
    "\n",
    "sister,sensor,level,product,datetime,in_crid = rfl_base_name.split('_')\n",
    "\n",
    "rfl_met = rfl_file.replace('.bin','.met.json')\n",
    "\n",
    "out_rfl_file =  f'{output_stac_catalog_dir}/SISTER_{sensor}_L2A_RSRFL_{datetime}_{crid}.bin'\n",
    "out_rfl_met = out_rfl_file.replace('.bin','.met.json')\n",
    "\n",
    "print(\"Reflectance File:\" + rfl_file)\n",
    "print(\"Output path:\" + out_rfl_met)\n",
    "\n",
    "\n",
    "sister,sensor,level,product,datetime,in_crid,subproduct = unc_base_name.split('_')\n",
    "\n",
    "unc_met = unc_file.replace('.bin','.met.json')\n",
    "\n",
    "out_unc_file =  f'{output_stac_catalog_dir}/SISTER_{sensor}_L2A_RSRFL_{datetime}_{crid}_UNC.bin'\n",
    "out_unc_met = out_unc_file.replace('.bin','.met.json')\n",
    "\n",
    "print(\"Uncertainty File:\" + unc_base_name)\n",
    "print(\"Output path:\" + out_unc_met)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f593bf2-8346-47b9-b5a3-91f3ae7742ce",
   "metadata": {},
   "source": [
    "Resampling Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56aff95-146b-4a4c-888f-039fb69ec290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing resampling alogrithm on Reflectance file...\n",
      "Aggregating every 1 bands\n",
      "Executing resampling alogrithm on Uncertainty file...\n",
      "Aggregating every 1 bands\n",
      "Generating quicklook on Reflectance file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Executing resampling alogrithm on Reflectance file...\")\n",
    "resample(rfl_file, out_rfl_file)\n",
    "\n",
    "print(\"Executing resampling alogrithm on Uncertainty file...\")\n",
    "resample(unc_file, out_unc_file)\n",
    "\n",
    "print(\"Generating quicklook on Reflectance file...\")\n",
    "generate_quicklook(out_rfl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc2b4e-65df-404e-b691-3a88a509abfb",
   "metadata": {},
   "source": [
    "Create stage-out item catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95612056-d202-4df3-af62-0a9f7a211dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Uncertain about this part. What is supposed to get sent out to STAC? \n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Create a collection\n",
    "out_collection = Collection(output_collection_name)\n",
    "\n",
    "# Add output file(s) to the dataset\n",
    "file = glob.glob(f\"{output_stac_catalog_dir}/*{crid}*.hdr\")\n",
    "\n",
    "if file:\n",
    "    header = envi.read_envi_header(file[0])    \n",
    "    start_time = dt.datetime.strptime(header['start acquisition time'], \"%Y-%m-%dt%H:%M:%Sz\")\n",
    "    end_time = dt.datetime.strptime(header['end acquisition time'], \"%Y-%m-%dt%H:%M:%Sz\")\n",
    "    # Create a Dataset for the collection\n",
    "    name = os.path.splitext(os.path.basename(file[0]))[0]\n",
    "    dataset = Dataset(\n",
    "        name=name,\n",
    "        collection_id=out_collection.collection_id, \n",
    "        start_time=start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        end_time=end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        creation_time=datetime.utcnow().replace(tzinfo=timezone.utc).isoformat(),\n",
    "        )\n",
    "    \n",
    "    for file in glob.glob(f\"{output_stac_catalog_dir}/*{crid}*\"):  \n",
    "\n",
    "        if file.endswith(\".bin\"):\n",
    "            dataset.add_data_file(DataFile(\"binary\", file, [\"data\"]))\n",
    "        elif file.endswith(\".png\"):\n",
    "            dataset.add_data_file(DataFile(\"image/png\", file, [\"browse\"]))\n",
    "        elif file.endswith(\".hdr\"):\n",
    "            dataset.add_data_file(DataFile(\"header\", file, [\"data\"]))\n",
    "        else:\n",
    "            dataset.add_data_file(DataFile(None, file, [\"metadata\"]))\n",
    "\n",
    "    dataset.add_data_file(DataFile(\"text/json\", output_stac_catalog_dir + '/' +  name +'.json', [\"metadata\"]))\n",
    "\n",
    "\n",
    "# Add the dataset to the collection\n",
    "out_collection._datasets.append(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2017b1c2-e466-4f4d-b36a-500cea35cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Collection.to_stac(out_collection, output_stac_catalog_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c728a-943e-4c73-8aa8-00017f39df5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
